{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (or simply ConvNets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNets are sparsely connected aritificial neural networks that deploy convolution operation in atleast one of the layers to learn patterns and are mainly used in image processing tasks (or data with grid like structure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of MLP?\n",
    "\n",
    "- Unable to preserve the image or in general grid-like structure of the input\n",
    "- Exponential scaling of the number of parameters with the input size.\n",
    "- Computationally intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MLP vs ConvNet.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **MLP VS ConvNet**<br></center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration\n",
    "ConvNets were inspired from the breakthrough achieved by Hubel and Wiesel in the area of sensory processing.\n",
    "<img src=\"Images/cat.png\" style=\"width:500px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 2** </u><font color='purple'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolutional Operation\n",
    "\n",
    "- $\\text{Input Volume and Filter} --> \\text{Feature Map}$\n",
    "- The operation is performed by superimposing a kernel tensor on a small region of the input tensor and then computing the elementwise multiplication of the tensors and summing the result.\n",
    "- Or it can be understood as a weighted sum of a range of pixels in a 2D image represented as a 2D matrix given a set of weights.\n",
    "- The purpose of the convolution operation is to approximate and learn the information present in those pixels or region or receptive field such as horizontal and vertical edge detection.\n",
    "\n",
    "- A kernel also known as a filter is a multidimensional array of parameters learned by the model. Each filter is responsible to learn some type of visual feature such as an edge of some particular orientation or some glob of color on the firtst layer or some complex feature later in the network.\n",
    "\n",
    "- The filter extends to the entire depth of the input and is moved across the entire input tensor by convolving/shifting it along the spatial (width and height) axes. \n",
    "- The size of the receptive field and the filter is always kept same to perform the operation.\n",
    "- The output of this operation is a 2D matrix <br><br>\n",
    "Mathematical formulation - <br><br>\n",
    "\n",
    "$S(i,j) = (I*K)(i,j) = \\sum_m \\sum_n I(i+m,j+n)\\odot K(m,n)$<br><br> \n",
    "\n",
    "Here S is the output matrix also known as the feature map, I is the input tensor and K is the filter\n",
    "\n",
    "\n",
    "<img src=\"images/Convolution_schematic.gif\" style=\"width:500px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 3** </u><font color='purple'>  : **Convolution operation**<br> with a filter of 2x2 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>\n",
    "    \n",
    "<b>Note</b> - The convolution operation in Machine Learning is the cross-correlation function in mathematics which is closely related to the convolution function.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/filters.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Visualizing filters from lower Conv Layers** </u><font color='purple'>\n",
    "\n",
    "\n",
    "<img src=\"Images/visuals.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Visualizing features and filters** </u><font color='purple'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The convolution Layer\n",
    "- It is the core building block of a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Interactions\n",
    "\n",
    "- In CNN, each neuron is connected to only a local region of the input volume\n",
    "- The spatial extent of this connectivity called the receptive field has to be determined.\n",
    "- Results in less number of paramters.\n",
    "\n",
    "### Parameter Sharing\n",
    "\n",
    "- The number of paramters in the Conv layer are drastically reduced by making a simple assumption:<br>\n",
    "<b>If detecting a feature is important at some spatial location in the image, then it must be useful at some other location also due to translation invariance property exhibited by an image.</b>  <br>\n",
    "- Hence in a Conv layer a filter is used across all the pixels in the input image (except sometimes leaving the border pixels) to compute the output or feature map.\n",
    "- Multiple filters are used to learn different feature maps. These feature maps are then stacked together across the depth to form the input volume of the next layer.\n",
    "\n",
    "### Equivariant representations\n",
    "\n",
    "- Paramter sharing causes the layer to acquire a property known as equivariance to translatioin.\n",
    "- According to this property, if we move the object in the input, its representations will also move in the output. Eg.- If a horizontal edge is present in one region then it is intuitive to assume that similar edges will be present across the image.\n",
    "- Convolutions are not naturally equivariant to some other kinds of transformations such as scaling or rotation. We use Pooling for such transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/activations.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 4** </u><font color='purple'>  : **Visualizing Activations and Feature Maps**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically a Conv Layer,\n",
    "- Accepts a volume of size $W_1×H_1×D_1$\n",
    "- Requires four hyperparameters:\n",
    "1. Number of filters $K$,\n",
    "2. their spatial extent $F$,\n",
    "3. the stride $S$,\n",
    "4. the amount of zero padding $P$.\n",
    "- Produces a volume of size $W_2×H_2×D_2$ where:\n",
    "1. $W_2=\\frac{(\\text{input_width}−\\text{Filter_width}+2*Padding)}{Stride}+1$\n",
    "2. $H_2=\\frac{(\\text{input_height}−\\text{Filter_height}+2*Padding)}{Stride}+1$ (i.e. width and height are computed equally by symmetry)\n",
    "3. $D_2=K$\n",
    "- With parameter sharing, it introduces $F⋅F⋅D_1$ weights per filter, for a total of $(F⋅F⋅D_1)⋅K$ weights and $K$ biases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "- Replaces a subset of the output of a layer at a certain location with a summary statistic of the nearby outputs.<br>\n",
    "- Reduces the spatial size of the output volume helping to -<br>\n",
    "1. Reduce the number of paramters to be learned by the next layer.\n",
    "2. Ensures invariance to small translations in the neighboring neurons.\n",
    "\n",
    "- If we pool over features learned by different filters i.e pool across the depth, the resulting feature can learn which transformations to become invariant to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two well known Pooling Techniques:\n",
    "#### Max Pooling \n",
    "In Max Pooling the maximum value from a selected neighborhood is used to represent the region.\n",
    "\n",
    "#### Average Pooling\n",
    "In Average Pooling, the average of all the values in the region is used to as the summary statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Pooling.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use case</b> -One major use of CNN is for the purpose of learning reapresentations which can be fed to another network for taks such as generating image captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/lenet.jpeg\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> **LeNet CNN Architecture** </u><font color='purple'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of CNNs\n",
    "- They are also prone to overfitting\n",
    "- Problem of Vanishing and exploding gradients with increase in depth\n",
    "- May overfit\n",
    "- Variable length inputs can not be given as input.\n",
    "- Increasing the depth does not always result in improved accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Architectures\n",
    "- LeNet\n",
    "- AlexNet\n",
    "- VGGNet\n",
    "- GoogLeNet\n",
    "- ResNet\n",
    "- DenseNet\n",
    "- ENet\n",
    "- Network in Network\n",
    "- MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
